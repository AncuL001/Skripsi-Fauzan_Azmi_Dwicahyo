{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from taco_dataset import CoCoDatasetForYOLO\n",
    "from config import Config\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=int(cfg.IMAGE_SIZE * cfg.scale)),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(cfg.IMAGE_SIZE * cfg.scale),\n",
    "            min_width=int(cfg.IMAGE_SIZE * cfg.scale),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.RandomCrop(width=cfg.IMAGE_SIZE, height=cfg.IMAGE_SIZE),\n",
    "        A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n",
    "                ),\n",
    "                A.Affine(shear=15, p=0.5, mode=cv2.BORDER_CONSTANT),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(p=0.1),\n",
    "        A.CLAHE(p=0.1),\n",
    "        A.Posterize(p=0.1),\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ChannelShuffle(p=0.05),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "\n",
    "    # got this error\n",
    "    # Expected y_min for bbox (0.5355392156862745, -0.00015318627450980338, 0.6523692810457516, 0.1803002450980392, 0) to be in the range [0.0, 1.0], got -0.00015318627450980338.\n",
    "    # rounding issue :/\n",
    "    # the insane solution to this problem (modifying the library code) https://github.com/albumentations-team/albumentations/issues/459#issuecomment-734454278\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[],),\n",
    ")\n",
    "\n",
    "train_dataset = CoCoDatasetForYOLO(\n",
    "    root=cfg.DATASET_PATH,\n",
    "    annFile=cfg.anns_file_path,\n",
    "    transform=train_transforms,\n",
    "    S=cfg.SPLIT_SIZE, B=cfg.NUM_BOXES, C=cfg.NUM_CLASSES\n",
    ")\n",
    "\n",
    "train_percentage = 0.8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1120,  820, 1119,  ...,  280,  615,  634])\n",
      "1199\n",
      "\n",
      "tensor([ 869, 1104, 1103, 1118,  819,  839,  822,  108,   43, 1151,  408,   34,\n",
      "         795,   69,  787,  705,  791,  519,   15,    1,  119,   45, 1123,   84,\n",
      "          47,  430,  532, 1132, 1462, 1364,    7, 1241,  656,  612,  388,  413,\n",
      "         843,  164,  383, 1464,  362, 1498,  182, 1124, 1135,  613,  628, 1190,\n",
      "        1411,  114, 1359, 1313,  632,  212,  564,  381,  166, 1063, 1320,  520,\n",
      "        1329, 1311,  410,  814,  531, 1170, 1312,  324,  261,  556,  389, 1361,\n",
      "         713,  265,  256,  169,  875,  263,  730, 1309, 1020,  682,  266, 1420,\n",
      "         718,  213,  456,  665,  283, 1323,  464,  993,  314,  365,  997,   56,\n",
      "        1212,  307,  973, 1263, 1262,  918,  907, 1259,  507, 1286, 1294,  984,\n",
      "         940,  923,  899,  778,  788,  917,  107,  407, 1432,  975,  908,  910,\n",
      "        1181,  896, 1310, 1196,  915,  972,  930,  906,  946,  989, 1003, 1292,\n",
      "          98,   99, 1470,  275,  379,  702,  239, 1040,  217, 1166, 1029, 1483,\n",
      "         475, 1269,  807,  831,   60,   28,  470, 1214,   10, 1476,  173, 1474,\n",
      "         567,  241,  766, 1143,  776,  167,  117, 1068,  759,  171,  782, 1389,\n",
      "        1062,  473,  835,  813, 1016, 1013,  373, 1226, 1060,  735, 1489,  179,\n",
      "         783,  370,  317,  571, 1469,  290,  577,  756, 1131,  856,  248,   85,\n",
      "         346, 1394,  594,  351, 1453,  982,  558,  146,  529, 1099, 1291, 1027,\n",
      "         394,  249, 1326,  606,  761, 1009, 1037, 1080,  229,  586, 1357,  254,\n",
      "        1188, 1348,  440,  416,  104,  349,  974,  403, 1094,  627,  703, 1479,\n",
      "        1023, 1484, 1354, 1375, 1057,  155,  187,  655,  278, 1424,  103,  398,\n",
      "        1177, 1229,  574,  376, 1183,  544, 1217,  186, 1165,  954, 1090, 1274,\n",
      "         546,  503,  542, 1058,  451,  154,  234,  434,  415, 1180, 1228,  629,\n",
      "        1448, 1069, 1115,   32,  686,  204, 1400,  704,  678,  809,  753, 1065,\n",
      "         153,  143, 1341,  476,  444, 1347, 1414,  722,  195, 1351,  391,  650,\n",
      "        1047,  350,  293,  999, 1495, 1303,  494, 1408,  881,  274,  657, 1137,\n",
      "          74])\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "from utils import get_stratified_indices\n",
    "\n",
    "train_indices, test_indices = get_stratified_indices(cfg.anns_file_path, len(train_dataset), train_percentage)\n",
    "\n",
    "print(train_indices)\n",
    "print(len(train_indices))\n",
    "print()\n",
    "print(test_indices)\n",
    "print(len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "curr_datetime = datetime.datetime.now()\n",
    "\n",
    "df = pd.DataFrame(train_indices, columns=['train_indices'])\n",
    "df.to_csv(f\"train_indices-{curr_datetime.strftime('%Y-%d-%m_%H-%M-%S')}.csv\", index=False)\n",
    "\n",
    "df2 = pd.DataFrame(test_indices, columns=['test_indices'])\n",
    "df2.to_csv(f\"test_indices-{curr_datetime.strftime('%Y-%d-%m_%H-%M-%S')}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True,  ..., True, True, True])\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(f\"train_indices-{curr_datetime.strftime('%Y-%d-%m_%H-%M-%S')}.csv\")\n",
    "train_indices2 = torch.tensor(df3['train_indices'].values)\n",
    "\n",
    "print(train_indices == train_indices2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
