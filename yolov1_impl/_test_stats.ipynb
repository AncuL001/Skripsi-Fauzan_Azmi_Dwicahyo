{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from models.resnet34_yolo import resnet34_yolo as used_model\n",
    "import config\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from utils import (\n",
    "    mean_average_precision,\n",
    "    get_bboxes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "    (4): Linear(in_features=4096, out_features=539, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../runs/ResNet/dropout-0.1/2023-02-12_14-14-14\"\n",
    "path_to_model = folder + \"/model.pt\"\n",
    "dropout = 0.1\n",
    "\n",
    "cfg = config.Config().replace(DROPOUT=dropout, BATCH_SIZE=16)\n",
    "model = used_model(split_size=cfg.SPLIT_SIZE, num_boxes=cfg.NUM_BOXES, num_classes=cfg.NUM_CLASSES, dropout_percentage=cfg.DROPOUT).to(cfg.DEVICE)\n",
    "model.load_state_dict(torch.load(path_to_model, map_location=torch.device(cfg.DEVICE)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "data_preprocess = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=IMAGE_SIZE),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\n",
    "        ),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../downloads/TACO/data'\n",
    "anns_file_path = DATASET_PATH + '/' + 'annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from taco_dataset import CoCoDatasetForYOLO\n",
    "\n",
    "test_dataset = CoCoDatasetForYOLO(\n",
    "    root=DATASET_PATH,\n",
    "    annFile=anns_file_path,\n",
    "    transform=data_preprocess,\n",
    "    C=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(cfg.test_indices_path)\n",
    "test_indices = torch.tensor(test_df['test_indices'].values)\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    num_workers=cfg.NUM_WORKERS,\n",
    "    pin_memory=cfg.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_boxes, target_boxes = get_bboxes(\n",
    "        test_loader, model, iou_threshold=cfg.iou_threshold, threshold=cfg.threshold, device=cfg.DEVICE,\n",
    "        S=cfg.SPLIT_SIZE, B=cfg.NUM_BOXES, C=cfg.NUM_CLASSES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import torch\n",
    "# from utils import intersection_over_union\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def mean_average_precision_a(\n",
    "#     pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20, print_output=False\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Calculates mean average precision \n",
    "\n",
    "#     Parameters:\n",
    "#         pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "#         specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "#         true_boxes (list): Similar as pred_boxes except all the correct ones \n",
    "#         iou_threshold (float): threshold where predicted bboxes is correct\n",
    "#         box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "#         num_classes (int): number of classes\n",
    "\n",
    "#     Returns:\n",
    "#         float: mAP value across all classes given a specific IoU threshold \n",
    "#     \"\"\"\n",
    "\n",
    "#     # list storing all AP for respective classes\n",
    "#     average_precisions = []\n",
    "\n",
    "#     # used for numerical stability later on\n",
    "#     epsilon = 1e-6\n",
    "\n",
    "#     for c in range(num_classes):\n",
    "#         detections = []\n",
    "#         ground_truths = []\n",
    "\n",
    "#         # Go through all predictions and targets,\n",
    "#         # and only add the ones that belong to the\n",
    "#         # current class c\n",
    "#         for detection in pred_boxes:\n",
    "#             if detection[1] == c:\n",
    "#                 detections.append(detection)\n",
    "\n",
    "#         for true_box in true_boxes:\n",
    "#             if true_box[1] == c:\n",
    "#                 ground_truths.append(true_box)\n",
    "\n",
    "#         # find the amount of bboxes for each training example\n",
    "#         # Counter here finds how many ground truth bboxes we get\n",
    "#         # for each training example, so let's say img 0 has 3,\n",
    "#         # img 1 has 5 then we will obtain a dictionary with:\n",
    "#         # amount_bboxes = {0:3, 1:5}\n",
    "#         amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "#         # We then go through each key, val in this dictionary\n",
    "#         # and convert to the following (w.r.t same example):\n",
    "#         # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
    "#         for key, val in amount_bboxes.items():\n",
    "#             amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "#         # sort by box probabilities which is index 2\n",
    "#         detections.sort(key=lambda x: x[2], reverse=True)\n",
    "#         TP = torch.zeros((len(detections)))\n",
    "#         FP = torch.zeros((len(detections)))\n",
    "#         total_true_bboxes = len(ground_truths)\n",
    "        \n",
    "#         # If none exists for this class then we can safely skip\n",
    "#         if total_true_bboxes == 0:\n",
    "#             continue\n",
    "\n",
    "#         for detection_idx, detection in enumerate(detections):\n",
    "#             # Only take out the ground_truths that have the same\n",
    "#             # training idx as detection\n",
    "#             ground_truth_img = [\n",
    "#                 bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "#             ]\n",
    "\n",
    "#             num_gts = len(ground_truth_img)\n",
    "#             best_iou = 0\n",
    "\n",
    "#             for idx, gt in enumerate(ground_truth_img):\n",
    "#                 iou = intersection_over_union(\n",
    "#                     torch.tensor(detection[3:]),\n",
    "#                     torch.tensor(gt[3:]),\n",
    "#                     box_format=box_format,\n",
    "#                 )\n",
    "\n",
    "#                 if iou > best_iou:\n",
    "#                     best_iou = iou\n",
    "#                     best_gt_idx = idx\n",
    "\n",
    "#             if best_iou > iou_threshold:\n",
    "#                 # only detect ground truth detection once\n",
    "#                 if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "#                     # true positive and add this bounding box to seen\n",
    "#                     TP[detection_idx] = 1\n",
    "#                     amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "#                 else:\n",
    "#                     FP[detection_idx] = 1\n",
    "\n",
    "#             # if IOU is lower then the detection is a false positive\n",
    "#             else:\n",
    "#                 FP[detection_idx] = 1\n",
    "\n",
    "#         TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "#         FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "#         recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "#         precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n",
    "#         precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "#         recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "#         # torch.trapz for numerical integration\n",
    "#         average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "#         if print_output:\n",
    "#             print(f\"Class: {c}\")\n",
    "\n",
    "#             print(f\"TP: {TP_cumsum[-1]}\")\n",
    "#             print(f\"FP: {FP_cumsum[-1]}\")\n",
    "#             print(f\"\\nTrue boxes: {total_true_bboxes}\")\n",
    "#             print(f\"\\nRecall: {recalls[-1]}\")\n",
    "#             print(f\"Precision: {precisions[-1]}\")\n",
    "\n",
    "#             plt.plot(recalls.tolist(), precisions.tolist())\n",
    "#             plt.fill_between(recalls.tolist(), precisions.tolist(), alpha=0.3)\n",
    "#             plt.grid()\n",
    "#             axes = plt.gca()\n",
    "#             axes.set_xlim([0,1])\n",
    "#             plt.show()\n",
    "\n",
    "#     return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "TP: 141.0\n",
      "FP: 344.0\n",
      "\n",
      "True boxes: 715\n",
      "\n",
      "Recall: 0.19720280170440674\n",
      "Precision: 0.2907216548919678\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1125)\n"
     ]
    }
   ],
   "source": [
    "mean_avg_prec = mean_average_precision(\n",
    "    pred_boxes, target_boxes, iou_threshold=cfg.iou_threshold, box_format=cfg.box_format, num_classes=cfg.NUM_CLASSES, print_output=True\n",
    ")\n",
    "\n",
    "print(mean_avg_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
